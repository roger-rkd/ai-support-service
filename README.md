---
title: AI Support Service
emoji: ğŸ¤–
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 8000
pinned: false
license: mit
tags:
  - rag
  - fastapi
  - groq
  - faiss
  - llm
  - support
  - chatbot
---

# ğŸ¤– AI Support Service with RAG Pipeline

> **An intelligent AI chatbot that answers customer support questions by learning from your company's FAQ documents**

Transform your customer support with an AI assistant that reads your documentation (PDF & TXT files) and provides instant, accurate answers 24/7.

**ğŸš€ Live Demo**: [https://huggingface.co/spaces/dubey-codes/ai-support-service](https://huggingface.co/spaces/dubey-codes/ai-support-service)

**ğŸ‘¨â€ğŸ’» Author**: Made with â¤ï¸ by **Rohit Kumar Dubey**
**ğŸ“¦ Repository**: [GitHub](https://github.com/roger-rkd/ai-support-service)

---

## âœ¨ Features

### Core Capabilities
- **ğŸ“„ PDF & TXT Support**: Upload your FAQ documents in PDF or text format
- **ğŸ¤– Smart AI Responses**: Powered by Groq's Llama 3.3 70B model for fast, accurate answers
- **ğŸ” Semantic Search**: FAISS vector search understands meaning, not just keywords
- **ğŸ’¬ Interactive Chat UI**: Beautiful, user-friendly web interface
- **ğŸ“Š Real-time Metrics**: Monitor performance with Prometheus metrics
- **ğŸš€ Production-Ready**: Docker support, Kubernetes manifests, health checks

### Technical Features
- **RAG Pipeline**: Retrieval Augmented Generation for contextual responses
- **Vector Embeddings**: Sentence Transformers for high-quality text understanding
- **RESTful API**: FastAPI with automatic OpenAPI documentation
- **Observability**: Prometheus metrics, request tracking, latency monitoring
- **CORS Enabled**: Ready for frontend integration

## ğŸ“ Project Structure

```
ai-support-service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ static/              # Frontend files
â”‚   â”‚   â””â”€â”€ index.html       # Interactive chat UI
â”‚   â”œâ”€â”€ rag/                 # RAG pipeline components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedder.py      # Document & query embedding
â”‚   â”‚   â”œâ”€â”€ retriever.py     # FAISS vector search (PDF + TXT)
â”‚   â”‚   â””â”€â”€ pipeline.py      # RAG orchestration
â”‚   â””â”€â”€ observability/       # Prometheus metrics
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ metrics.py
â”œâ”€â”€ data/                    # ğŸ“„ Add your FAQ files here (.txt or .pdf)
â”‚   â”œâ”€â”€ faq_password.txt
â”‚   â”œâ”€â”€ faq_account.txt
â”‚   â”œâ”€â”€ faq_billing.txt
â”‚   â”œâ”€â”€ faq_technical.txt
â”‚   â””â”€â”€ company_policies.pdf # ğŸ‘ˆ PDF files supported!
â”œâ”€â”€ k8s/                     # Kubernetes deployment manifests
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â””â”€â”€ secret.yaml.template
â”œâ”€â”€ observability/           # Monitoring stack
â”‚   â”œâ”€â”€ docker-compose.yml   # Prometheus + Grafana
â”‚   â””â”€â”€ grafana-dashboard.json
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## Setup Instructions

### 1. Prerequisites

- Python 3.12 (recommended)
- Git
- Groq API key (get from [console.groq.com](https://console.groq.com/keys))

### 2. Installation

```bash
# Create virtual environment with Python 3.12
py -3.12 -m venv venv

# Activate virtual environment (Windows)
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

Create a `.env` file:

```bash
copy .env.example .env
```

Edit `.env` and add your Groq API key:

```env
GROQ_API_KEY=your_actual_groq_api_key_here
```

### 4. Run the Application

```bash
uvicorn app.main:app --reload
```

The service will be available at:
- **ğŸ’¬ Interactive Chat**: http://localhost:8000
- **ğŸ“– API Docs**: http://localhost:8000/docs
- **ğŸ“Š Metrics**: http://localhost:8000/metrics
- **ğŸ¥ Health Check**: http://localhost:8000/health

---

## ğŸ“„ Adding Your FAQ Documents

### Supported Formats
- **Text Files** (`.txt`): Plain text FAQs
- **PDF Files** (`.pdf`): **NEW!** Upload your PDF documentation

### How to Add Documents

1. **Place files in the `/data` folder**:
   ```bash
   data/
   â”œâ”€â”€ faq_password.txt
   â”œâ”€â”€ faq_billing.txt
   â”œâ”€â”€ company_policies.pdf    # ğŸ‘ˆ PDF support!
   â””â”€â”€ user_guide.pdf           # ğŸ‘ˆ PDF support!
   ```

2. **Rebuild the index** (automatic on restart):
   ```bash
   # Restart the application
   uvicorn app.main:app --reload
   ```

3. **Or rebuild manually via Python**:
   ```python
   from app.rag.pipeline import rebuild_index
   rebuild_index()
   ```

### Document Tips
- âœ… **Use clear, well-formatted documents**
- âœ… **One topic per file recommended** (e.g., `billing.pdf`, `passwords.txt`)
- âœ… **PDFs with searchable text work best** (not scanned images)
- âœ… **Keep documents focused and concise**

---

## ğŸ’¬ Using the Chat Interface

1. Open http://localhost:8000 in your browser
2. Try the example questions or type your own
3. Get instant AI-powered answers based on your FAQ documents

**Example Questions:**
- "How do I reset my password?"
- "What are your billing policies?"
- "How can I update my account information?"
- "What are your support hours?"

---

## API Endpoints

### POST /ask - Ask a Question

```json
{
  "question": "How do I reset my password?"
}
```

Response:
```json
{
  "answer": "To reset your password, follow these steps: 1. Go to the login page..."
}
```

### GET /health - Health Check

```json
{
  "status": "ok"
}
```

## ğŸ”§ How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Load Documents (PDF/TXT) â†’ Parse & Extract Text         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Generate Embeddings â†’ Convert text to vectors           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Store in FAISS Index â†’ Fast similarity search           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. User Asks Question â†’ Convert to vector                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. Search Similar Docs â†’ Retrieve top-3 matches            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. Generate Answer â†’ Groq AI with context                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step-by-Step Process

1. **ğŸ“„ Document Loading**: All `.txt` and `.pdf` files in `data/` are loaded and parsed
2. **ğŸ§® Embedding**: Documents converted to vector embeddings using `all-MiniLM-L6-v2`
3. **ğŸ’¾ Indexing**: Embeddings stored in FAISS index for fast retrieval
4. **â“ Query**: User question â†’ embedding â†’ retrieve top-3 relevant docs
5. **ğŸ¤– Generation**: Groq's Llama 3.3 70B generates answer using retrieved context

## ğŸ› ï¸ Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Web Framework** | FastAPI | High-performance REST API |
| **AI Model** | Groq (Llama 3.3 70B) | Fast LLM inference |
| **Embeddings** | Sentence Transformers | Text-to-vector conversion |
| **Vector DB** | FAISS | Similarity search |
| **PDF Parser** | PyPDF | Extract text from PDFs |
| **Metrics** | Prometheus | Observability |
| **Validation** | Pydantic | Request/response models |

## Docker Deployment

### Quick Start with Docker Compose

```bash
# Build and run with docker-compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop the service
docker-compose down
```

### Build and Run with Docker

```bash
# Build the image
docker build -t ai-support-service .

# Run the container
docker run -d \
  --name ai-support-service \
  -p 8000:8000 \
  -e GROQ_API_KEY=your_groq_api_key \
  -v $(pwd)/data:/app/data \
  ai-support-service

# View logs
docker logs -f ai-support-service

# Stop the container
docker stop ai-support-service
docker rm ai-support-service
```

### Docker Image Features

- **Small size**: Based on `python:3.11-slim`
- **Security**: Runs as non-root user
- **Health checks**: Automatic health monitoring
- **Production-ready**: Optimized for performance
- **Layer caching**: Fast rebuilds during development

### Environment Variables

Pass environment variables when running the container:

```bash
docker run -d \
  -p 8000:8000 \
  -e GROQ_API_KEY=your_key \
  -e EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2 \
  ai-support-service
```

Or use a `.env` file with docker-compose (recommended).

## Production Deployment

### Cloud Deployment Options

**AWS ECS/Fargate:**
```bash
# Tag and push to ECR
docker tag ai-support-service:latest <aws_account_id>.dkr.ecr.region.amazonaws.com/ai-support-service:latest
docker push <aws_account_id>.dkr.ecr.region.amazonaws.com/ai-support-service:latest
```

**Google Cloud Run:**
```bash
gcloud run deploy ai-support-service \
  --image ai-support-service:latest \
  --platform managed \
  --set-env-vars GROQ_API_KEY=your_key
```

**Azure Container Instances:**
```bash
az container create \
  --resource-group myResourceGroup \
  --name ai-support-service \
  --image ai-support-service:latest \
  --environment-variables GROQ_API_KEY=your_key
```

### Kubernetes Deployment

Create a `deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-support-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-support-service
  template:
    metadata:
      labels:
        app: ai-support-service
    spec:
      containers:
      - name: ai-support-service
        image: ai-support-service:latest
        ports:
        - containerPort: 8000
        env:
        - name: GROQ_API_KEY
          valueFrom:
            secretKeyRef:
              name: groq-secret
              key: api-key
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 40
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 20
          periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: ai-support-service
spec:
  selector:
    app: ai-support-service
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

Apply:
```bash
kubectl apply -f deployment.yaml
```
